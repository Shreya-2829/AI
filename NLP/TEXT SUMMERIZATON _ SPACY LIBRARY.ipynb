{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.9 MB 5.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/13.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.5/13.9 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.6/13.9 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.1/13.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.7/13.9 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.2/13.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.0/13.9 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.3/13.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.9 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.4/13.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl (116 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.5/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.4/6.3 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.4 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 numpy-2.3.2 preshed-3.0.10 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\shreya\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'C:\\Users\\shreya\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\shreya\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.3.2 which is incompatible.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "#(we have 3 type of model is available called small, medium & large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\shreya\\appdata\\roaming\\python\\python312\\site-packages (2.3.2)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (3.11.0)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 18.4 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 31.0 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.7/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"data science and ai has great career ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data science and ai has great career ahead"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "science\n",
      "and\n",
      "ai\n",
      "has\n",
      "great\n",
      "career\n",
      "ahead\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP nsubj X.X. False False\n",
      "startup startup VERB VBD ccomp xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "AUX\n",
      "VERB\n",
      "ADP\n",
      "VERB\n",
      "PROPN\n",
      "VERB\n",
      "ADP\n",
      "SYM\n",
      "NUM\n",
      "NUM\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN\n",
      "is AUX\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.K. PROPN\n",
      "startup VERB\n",
      "for ADP\n",
      "$ SYM\n",
      "1 NUM\n",
      "billion NUM\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN Apple\n",
      "is AUX be\n",
      "looking VERB look\n",
      "at ADP at\n",
      "buying VERB buy\n",
      "U.K. PROPN U.K.\n",
      "startup VERB startup\n",
      "for ADP for\n",
      "$ SYM $\n",
      "1 NUM 1\n",
      "billion NUM billion\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['which',\n",
       " 'herein',\n",
       " 'see',\n",
       " 'n’t',\n",
       " 'who',\n",
       " 'everything',\n",
       " 'nine',\n",
       " 'just',\n",
       " 'serious',\n",
       " '‘m',\n",
       " 'whom',\n",
       " 'where',\n",
       " '’d',\n",
       " 'beforehand',\n",
       " 'beside',\n",
       " 'this',\n",
       " 'to',\n",
       " 'has',\n",
       " 'all',\n",
       " '‘s',\n",
       " 'other',\n",
       " 'hence',\n",
       " 'since',\n",
       " 'everyone',\n",
       " 'give',\n",
       " 'whereas',\n",
       " 'own',\n",
       " 'yours',\n",
       " 'part',\n",
       " 'done',\n",
       " 'being',\n",
       " 'together',\n",
       " 'always',\n",
       " 'sometime',\n",
       " 'therein',\n",
       " 'i',\n",
       " 'former',\n",
       " '‘re',\n",
       " 'seems',\n",
       " 'amongst',\n",
       " 'twelve',\n",
       " 'may',\n",
       " 'most',\n",
       " 'used',\n",
       " 'those',\n",
       " 'whether',\n",
       " 'put',\n",
       " '’re',\n",
       " 'others',\n",
       " 'can',\n",
       " 'per',\n",
       " \"'d\",\n",
       " 'becomes',\n",
       " 'fifteen',\n",
       " 'next',\n",
       " 'hereupon',\n",
       " 'becoming',\n",
       " 'does',\n",
       " 'hereby',\n",
       " 'twenty',\n",
       " 'until',\n",
       " 'yourselves',\n",
       " 'please',\n",
       " 'itself',\n",
       " 'though',\n",
       " 'last',\n",
       " 'unless',\n",
       " 'move',\n",
       " 'is',\n",
       " 'many',\n",
       " 'throughout',\n",
       " 'will',\n",
       " 'whole',\n",
       " 'eight',\n",
       " 'it',\n",
       " 'become',\n",
       " 'none',\n",
       " 'could',\n",
       " 'mine',\n",
       " 'into',\n",
       " 'nothing',\n",
       " 'still',\n",
       " 'quite',\n",
       " 'through',\n",
       " 'sometimes',\n",
       " 'under',\n",
       " 'two',\n",
       " 'whoever',\n",
       " 'beyond',\n",
       " 'bottom',\n",
       " 'thus',\n",
       " 'n‘t',\n",
       " 'first',\n",
       " 'eleven',\n",
       " 'rather',\n",
       " 'its',\n",
       " 'nevertheless',\n",
       " 'our',\n",
       " 'nor',\n",
       " 'between',\n",
       " 'afterwards',\n",
       " 'enough',\n",
       " 'ten',\n",
       " 'off',\n",
       " 'hers',\n",
       " 'even',\n",
       " 'your',\n",
       " 'hundred',\n",
       " 'mostly',\n",
       " 'every',\n",
       " 'so',\n",
       " 'ourselves',\n",
       " 'go',\n",
       " 'what',\n",
       " 'amount',\n",
       " 'whenever',\n",
       " 'ca',\n",
       " 'make',\n",
       " 'among',\n",
       " 'both',\n",
       " 'behind',\n",
       " 'whereafter',\n",
       " 'seeming',\n",
       " '‘ve',\n",
       " 'she',\n",
       " 'although',\n",
       " 'thence',\n",
       " 'after',\n",
       " 'due',\n",
       " 'well',\n",
       " 'but',\n",
       " 'therefore',\n",
       " 'doing',\n",
       " 'why',\n",
       " 'seemed',\n",
       " 'no',\n",
       " 'whereupon',\n",
       " '’m',\n",
       " 'an',\n",
       " 'when',\n",
       " 'should',\n",
       " 'somewhere',\n",
       " 'anywhere',\n",
       " 'sixty',\n",
       " 'another',\n",
       " 'also',\n",
       " 'we',\n",
       " 'by',\n",
       " 'during',\n",
       " 'the',\n",
       " 'that',\n",
       " 'say',\n",
       " 'him',\n",
       " 'anyhow',\n",
       " 'be',\n",
       " 'made',\n",
       " 'otherwise',\n",
       " 'same',\n",
       " 'somehow',\n",
       " '‘ll',\n",
       " 'least',\n",
       " \"'ll\",\n",
       " 'are',\n",
       " 'whence',\n",
       " 'about',\n",
       " 'except',\n",
       " 'few',\n",
       " 'take',\n",
       " 'hereafter',\n",
       " 'you',\n",
       " 'formerly',\n",
       " 'now',\n",
       " 'various',\n",
       " 'been',\n",
       " 'one',\n",
       " 'their',\n",
       " 'noone',\n",
       " 'within',\n",
       " 'really',\n",
       " 'alone',\n",
       " 'themselves',\n",
       " 'anyway',\n",
       " 'perhaps',\n",
       " 'up',\n",
       " 'a',\n",
       " 'yourself',\n",
       " 'get',\n",
       " \"'s\",\n",
       " 'any',\n",
       " 'never',\n",
       " 'latter',\n",
       " '‘d',\n",
       " 'nobody',\n",
       " 'have',\n",
       " 'show',\n",
       " 'indeed',\n",
       " 'again',\n",
       " 'whose',\n",
       " 'himself',\n",
       " 'each',\n",
       " 'cannot',\n",
       " 'full',\n",
       " 'much',\n",
       " 'must',\n",
       " 'am',\n",
       " 'such',\n",
       " 'while',\n",
       " 'only',\n",
       " 'below',\n",
       " 'everywhere',\n",
       " 'at',\n",
       " 'further',\n",
       " 'yet',\n",
       " 'forty',\n",
       " 'once',\n",
       " 'however',\n",
       " 'back',\n",
       " 'moreover',\n",
       " 'besides',\n",
       " 'thereupon',\n",
       " 'often',\n",
       " 'thru',\n",
       " 'elsewhere',\n",
       " 'very',\n",
       " 'thereafter',\n",
       " 'and',\n",
       " 'someone',\n",
       " 'less',\n",
       " \"'re\",\n",
       " 'they',\n",
       " 'them',\n",
       " 'without',\n",
       " 'did',\n",
       " 'anything',\n",
       " 'three',\n",
       " 'wherein',\n",
       " 'us',\n",
       " 'four',\n",
       " 'do',\n",
       " 'her',\n",
       " 'as',\n",
       " 'if',\n",
       " 'he',\n",
       " 'side',\n",
       " 'here',\n",
       " '’ll',\n",
       " 'regarding',\n",
       " 'latterly',\n",
       " 'over',\n",
       " 'might',\n",
       " 'were',\n",
       " 'towards',\n",
       " 'top',\n",
       " 'seem',\n",
       " 're',\n",
       " 'anyone',\n",
       " 'out',\n",
       " 'above',\n",
       " 'in',\n",
       " 'whereby',\n",
       " 'whither',\n",
       " 'along',\n",
       " 'already',\n",
       " 'third',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'had',\n",
       " 'thereby',\n",
       " 'nowhere',\n",
       " 'or',\n",
       " \"'ve\",\n",
       " 'onto',\n",
       " 'of',\n",
       " 'there',\n",
       " '’ve',\n",
       " 'almost',\n",
       " 'something',\n",
       " 'from',\n",
       " 'for',\n",
       " 'else',\n",
       " 'six',\n",
       " \"'m\",\n",
       " 'meanwhile',\n",
       " 'against',\n",
       " 'toward',\n",
       " 'whatever',\n",
       " 'then',\n",
       " 'with',\n",
       " 'would',\n",
       " 'because',\n",
       " 'on',\n",
       " 'down',\n",
       " 'via',\n",
       " 'empty',\n",
       " 'namely',\n",
       " 'front',\n",
       " 'ever',\n",
       " 'several',\n",
       " '’s',\n",
       " 'wherever',\n",
       " 'herself',\n",
       " 'than',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'five',\n",
       " 'my',\n",
       " 'more',\n",
       " 'too',\n",
       " 'call',\n",
       " 'how',\n",
       " 'these',\n",
       " 'before',\n",
       " 'ours',\n",
       " 'either',\n",
       " 'around',\n",
       " 'fifty',\n",
       " \"n't\",\n",
       " 'across',\n",
       " 'neither',\n",
       " 'was',\n",
       " 'using',\n",
       " 'not',\n",
       " 'became',\n",
       " 'me',\n",
       " 'keep',\n",
       " 'some']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS) \n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
     ]
    }
   ],
   "source": [
    "# lets get the tokens from text\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens) \n",
    "#when we execute everythihg we created tokens from the text & not removed any of the stopwords & didnt cleaned the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'are',\n",
       " 'broadly',\n",
       " 'two',\n",
       " 'types',\n",
       " 'of',\n",
       " 'extractive',\n",
       " 'summarization',\n",
       " 'tasks',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'summarization',\n",
       " 'program',\n",
       " 'focuses',\n",
       " 'on',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'is',\n",
       " 'generic',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'obtaining',\n",
       " 'a',\n",
       " 'generic',\n",
       " 'summary',\n",
       " 'or',\n",
       " 'abstract',\n",
       " 'of',\n",
       " 'the',\n",
       " 'collection',\n",
       " '(',\n",
       " 'whether',\n",
       " 'documents',\n",
       " ',',\n",
       " 'or',\n",
       " 'sets',\n",
       " 'of',\n",
       " 'images',\n",
       " ',',\n",
       " 'or',\n",
       " 'videos',\n",
       " ',',\n",
       " 'news',\n",
       " 'stories',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'is',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'called',\n",
       " 'query',\n",
       " '-',\n",
       " 'based',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'summarizes',\n",
       " 'objects',\n",
       " 'specific',\n",
       " 'to',\n",
       " 'a',\n",
       " 'query',\n",
       " '.',\n",
       " 'Summarization',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'able',\n",
       " 'to',\n",
       " 'create',\n",
       " 'both',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'text',\n",
       " 'summaries',\n",
       " 'and',\n",
       " 'generic',\n",
       " 'machine',\n",
       " '-',\n",
       " 'generated',\n",
       " 'summaries',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'user',\n",
       " 'needs',\n",
       " '.',\n",
       " '\\n',\n",
       " 'An',\n",
       " 'example',\n",
       " 'of',\n",
       " 'a',\n",
       " 'summarization',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'document',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'produce',\n",
       " 'an',\n",
       " 'abstract',\n",
       " 'from',\n",
       " 'a',\n",
       " 'given',\n",
       " 'document',\n",
       " '.',\n",
       " 'Sometimes',\n",
       " 'one',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'generating',\n",
       " 'a',\n",
       " 'summary',\n",
       " 'from',\n",
       " 'a',\n",
       " 'single',\n",
       " 'source',\n",
       " 'document',\n",
       " ',',\n",
       " 'while',\n",
       " 'others',\n",
       " 'can',\n",
       " 'use',\n",
       " 'multiple',\n",
       " 'source',\n",
       " 'documents',\n",
       " '(',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'a',\n",
       " 'cluster',\n",
       " 'of',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'topic',\n",
       " ')',\n",
       " '.',\n",
       " 'This',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'called',\n",
       " 'multi',\n",
       " '-',\n",
       " 'document',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'A',\n",
       " 'related',\n",
       " 'application',\n",
       " 'is',\n",
       " 'summarizing',\n",
       " 'news',\n",
       " 'articles',\n",
       " '.',\n",
       " 'Imagine',\n",
       " 'a',\n",
       " 'system',\n",
       " ',',\n",
       " 'which',\n",
       " 'automatically',\n",
       " 'pulls',\n",
       " 'together',\n",
       " 'news',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'a',\n",
       " 'given',\n",
       " 'topic',\n",
       " '(',\n",
       " 'from',\n",
       " 'the',\n",
       " 'web',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'concisely',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'news',\n",
       " 'as',\n",
       " 'a',\n",
       " 'summary',\n",
       " '.',\n",
       " '\\n',\n",
       " 'Image',\n",
       " 'collection',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'another',\n",
       " 'application',\n",
       " 'example',\n",
       " 'of',\n",
       " 'automatic',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'It',\n",
       " 'consists',\n",
       " 'in',\n",
       " 'selecting',\n",
       " 'a',\n",
       " 'representative',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images',\n",
       " 'from',\n",
       " 'a',\n",
       " 'larger',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images.[4',\n",
       " ']',\n",
       " 'A',\n",
       " 'summary',\n",
       " 'in',\n",
       " 'this',\n",
       " 'context',\n",
       " 'is',\n",
       " 'useful',\n",
       " 'to',\n",
       " 'show',\n",
       " 'the',\n",
       " 'most',\n",
       " 'representative',\n",
       " 'images',\n",
       " 'of',\n",
       " 'results',\n",
       " 'in',\n",
       " 'an',\n",
       " 'image',\n",
       " 'collection',\n",
       " 'exploration',\n",
       " 'system',\n",
       " '.',\n",
       " 'Video',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'related',\n",
       " 'domain',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " 'system',\n",
       " 'automatically',\n",
       " 'creates',\n",
       " 'a',\n",
       " 'trailer',\n",
       " 'of',\n",
       " 'a',\n",
       " 'long',\n",
       " 'video',\n",
       " '.',\n",
       " 'This',\n",
       " 'also',\n",
       " 'has',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'consumer',\n",
       " 'or',\n",
       " 'personal',\n",
       " 'videos',\n",
       " ',',\n",
       " 'where',\n",
       " 'one',\n",
       " 'might',\n",
       " 'want',\n",
       " 'to',\n",
       " 'skip',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'or',\n",
       " 'repetitive',\n",
       " 'actions',\n",
       " '.',\n",
       " 'Similarly',\n",
       " ',',\n",
       " 'in',\n",
       " 'surveillance',\n",
       " 'videos',\n",
       " ',',\n",
       " 'one',\n",
       " 'would',\n",
       " 'want',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'important',\n",
       " 'and',\n",
       " 'suspicious',\n",
       " 'activity',\n",
       " ',',\n",
       " 'while',\n",
       " 'ignoring',\n",
       " 'all',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'and',\n",
       " 'redundant',\n",
       " 'frames',\n",
       " 'captured']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation # also called as noisy  characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to calcualte the freaquency of each and every word, how many time word is repetation in text \n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 11,\n",
       " 'tasks': 1,\n",
       " 'depending': 2,\n",
       " 'program': 1,\n",
       " 'focuses': 2,\n",
       " 'generic': 3,\n",
       " 'obtaining': 1,\n",
       " 'summary': 4,\n",
       " 'abstract': 2,\n",
       " 'collection': 3,\n",
       " 'documents': 2,\n",
       " 'sets': 1,\n",
       " 'images': 3,\n",
       " 'videos': 3,\n",
       " 'news': 4,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 4,\n",
       " 'relevant': 2,\n",
       " 'called': 2,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1,\n",
       " 'Summarization': 1,\n",
       " 'systems': 1,\n",
       " 'able': 1,\n",
       " 'create': 1,\n",
       " 'text': 1,\n",
       " 'summaries': 2,\n",
       " 'machine': 1,\n",
       " 'generated': 1,\n",
       " 'user': 1,\n",
       " 'needs': 1,\n",
       " '\\n': 2,\n",
       " 'example': 3,\n",
       " 'problem': 2,\n",
       " 'document': 4,\n",
       " 'attempts': 1,\n",
       " 'automatically': 3,\n",
       " 'produce': 1,\n",
       " 'given': 2,\n",
       " 'interested': 1,\n",
       " 'generating': 1,\n",
       " 'single': 1,\n",
       " 'source': 2,\n",
       " 'use': 1,\n",
       " 'multiple': 1,\n",
       " 'cluster': 1,\n",
       " 'articles': 3,\n",
       " 'topic': 2,\n",
       " 'multi': 1,\n",
       " 'related': 2,\n",
       " 'application': 2,\n",
       " 'summarizing': 1,\n",
       " 'Imagine': 1,\n",
       " 'system': 3,\n",
       " 'pulls': 1,\n",
       " 'web': 1,\n",
       " 'concisely': 1,\n",
       " 'represents': 1,\n",
       " 'latest': 1,\n",
       " 'Image': 1,\n",
       " 'automatic': 1,\n",
       " 'consists': 1,\n",
       " 'selecting': 1,\n",
       " 'representative': 2,\n",
       " 'set': 2,\n",
       " 'larger': 1,\n",
       " 'images.[4': 1,\n",
       " 'context': 1,\n",
       " 'useful': 1,\n",
       " 'results': 1,\n",
       " 'image': 1,\n",
       " 'exploration': 1,\n",
       " 'Video': 1,\n",
       " 'domain': 1,\n",
       " 'creates': 1,\n",
       " 'trailer': 1,\n",
       " 'long': 1,\n",
       " 'video': 1,\n",
       " 'applications': 1,\n",
       " 'consumer': 1,\n",
       " 'personal': 1,\n",
       " 'want': 2,\n",
       " 'skip': 1,\n",
       " 'boring': 2,\n",
       " 'repetitive': 1,\n",
       " 'actions': 1,\n",
       " 'Similarly': 1,\n",
       " 'surveillance': 1,\n",
       " 'extract': 1,\n",
       " 'important': 1,\n",
       " 'suspicious': 1,\n",
       " 'activity': 1,\n",
       " 'ignoring': 1,\n",
       " 'redundant': 1,\n",
       " 'frames': 1,\n",
       " 'captured': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies\n",
    "#print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequencies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 11,\n",
       " 'tasks': 1,\n",
       " 'depending': 2,\n",
       " 'program': 1,\n",
       " 'focuses': 2,\n",
       " 'generic': 3,\n",
       " 'obtaining': 1,\n",
       " 'summary': 4,\n",
       " 'abstract': 2,\n",
       " 'collection': 3,\n",
       " 'documents': 2,\n",
       " 'sets': 1,\n",
       " 'images': 3,\n",
       " 'videos': 3,\n",
       " 'news': 4,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 4,\n",
       " 'relevant': 2,\n",
       " 'called': 2,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1,\n",
       " 'Summarization': 1,\n",
       " 'systems': 1,\n",
       " 'able': 1,\n",
       " 'create': 1,\n",
       " 'text': 1,\n",
       " 'summaries': 2,\n",
       " 'machine': 1,\n",
       " 'generated': 1,\n",
       " 'user': 1,\n",
       " 'needs': 1,\n",
       " '\\n': 2,\n",
       " 'example': 3,\n",
       " 'problem': 2,\n",
       " 'document': 4,\n",
       " 'attempts': 1,\n",
       " 'automatically': 3,\n",
       " 'produce': 1,\n",
       " 'given': 2,\n",
       " 'interested': 1,\n",
       " 'generating': 1,\n",
       " 'single': 1,\n",
       " 'source': 2,\n",
       " 'use': 1,\n",
       " 'multiple': 1,\n",
       " 'cluster': 1,\n",
       " 'articles': 3,\n",
       " 'topic': 2,\n",
       " 'multi': 1,\n",
       " 'related': 2,\n",
       " 'application': 2,\n",
       " 'summarizing': 1,\n",
       " 'Imagine': 1,\n",
       " 'system': 3,\n",
       " 'pulls': 1,\n",
       " 'web': 1,\n",
       " 'concisely': 1,\n",
       " 'represents': 1,\n",
       " 'latest': 1,\n",
       " 'Image': 1,\n",
       " 'automatic': 1,\n",
       " 'consists': 1,\n",
       " 'selecting': 1,\n",
       " 'representative': 2,\n",
       " 'set': 2,\n",
       " 'larger': 1,\n",
       " 'images.[4': 1,\n",
       " 'context': 1,\n",
       " 'useful': 1,\n",
       " 'results': 1,\n",
       " 'image': 1,\n",
       " 'exploration': 1,\n",
       " 'Video': 1,\n",
       " 'domain': 1,\n",
       " 'creates': 1,\n",
       " 'trailer': 1,\n",
       " 'long': 1,\n",
       " 'video': 1,\n",
       " 'applications': 1,\n",
       " 'consumer': 1,\n",
       " 'personal': 1,\n",
       " 'want': 2,\n",
       " 'skip': 1,\n",
       " 'boring': 2,\n",
       " 'repetitive': 1,\n",
       " 'actions': 1,\n",
       " 'Similarly': 1,\n",
       " 'surveillance': 1,\n",
       " 'extract': 1,\n",
       " 'important': 1,\n",
       " 'suspicious': 1,\n",
       " 'activity': 1,\n",
       " 'ignoring': 1,\n",
       " 'redundant': 1,\n",
       " 'frames': 1,\n",
       " 'captured': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get normalized/weighted frequencies you should devide all frequencies with 11\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 0.09090909090909091,\n",
       " 'types': 0.09090909090909091,\n",
       " 'extractive': 0.09090909090909091,\n",
       " 'summarization': 1.0,\n",
       " 'tasks': 0.09090909090909091,\n",
       " 'depending': 0.18181818181818182,\n",
       " 'program': 0.09090909090909091,\n",
       " 'focuses': 0.18181818181818182,\n",
       " 'generic': 0.2727272727272727,\n",
       " 'obtaining': 0.09090909090909091,\n",
       " 'summary': 0.36363636363636365,\n",
       " 'abstract': 0.18181818181818182,\n",
       " 'collection': 0.2727272727272727,\n",
       " 'documents': 0.18181818181818182,\n",
       " 'sets': 0.09090909090909091,\n",
       " 'images': 0.2727272727272727,\n",
       " 'videos': 0.2727272727272727,\n",
       " 'news': 0.36363636363636365,\n",
       " 'stories': 0.09090909090909091,\n",
       " 'etc': 0.09090909090909091,\n",
       " 'second': 0.09090909090909091,\n",
       " 'query': 0.36363636363636365,\n",
       " 'relevant': 0.18181818181818182,\n",
       " 'called': 0.18181818181818182,\n",
       " 'based': 0.09090909090909091,\n",
       " 'summarizes': 0.09090909090909091,\n",
       " 'objects': 0.09090909090909091,\n",
       " 'specific': 0.09090909090909091,\n",
       " 'Summarization': 0.09090909090909091,\n",
       " 'systems': 0.09090909090909091,\n",
       " 'able': 0.09090909090909091,\n",
       " 'create': 0.09090909090909091,\n",
       " 'text': 0.09090909090909091,\n",
       " 'summaries': 0.18181818181818182,\n",
       " 'machine': 0.09090909090909091,\n",
       " 'generated': 0.09090909090909091,\n",
       " 'user': 0.09090909090909091,\n",
       " 'needs': 0.09090909090909091,\n",
       " '\\n': 0.18181818181818182,\n",
       " 'example': 0.2727272727272727,\n",
       " 'problem': 0.18181818181818182,\n",
       " 'document': 0.36363636363636365,\n",
       " 'attempts': 0.09090909090909091,\n",
       " 'automatically': 0.2727272727272727,\n",
       " 'produce': 0.09090909090909091,\n",
       " 'given': 0.18181818181818182,\n",
       " 'interested': 0.09090909090909091,\n",
       " 'generating': 0.09090909090909091,\n",
       " 'single': 0.09090909090909091,\n",
       " 'source': 0.18181818181818182,\n",
       " 'use': 0.09090909090909091,\n",
       " 'multiple': 0.09090909090909091,\n",
       " 'cluster': 0.09090909090909091,\n",
       " 'articles': 0.2727272727272727,\n",
       " 'topic': 0.18181818181818182,\n",
       " 'multi': 0.09090909090909091,\n",
       " 'related': 0.18181818181818182,\n",
       " 'application': 0.18181818181818182,\n",
       " 'summarizing': 0.09090909090909091,\n",
       " 'Imagine': 0.09090909090909091,\n",
       " 'system': 0.2727272727272727,\n",
       " 'pulls': 0.09090909090909091,\n",
       " 'web': 0.09090909090909091,\n",
       " 'concisely': 0.09090909090909091,\n",
       " 'represents': 0.09090909090909091,\n",
       " 'latest': 0.09090909090909091,\n",
       " 'Image': 0.09090909090909091,\n",
       " 'automatic': 0.09090909090909091,\n",
       " 'consists': 0.09090909090909091,\n",
       " 'selecting': 0.09090909090909091,\n",
       " 'representative': 0.18181818181818182,\n",
       " 'set': 0.18181818181818182,\n",
       " 'larger': 0.09090909090909091,\n",
       " 'images.[4': 0.09090909090909091,\n",
       " 'context': 0.09090909090909091,\n",
       " 'useful': 0.09090909090909091,\n",
       " 'results': 0.09090909090909091,\n",
       " 'image': 0.09090909090909091,\n",
       " 'exploration': 0.09090909090909091,\n",
       " 'Video': 0.09090909090909091,\n",
       " 'domain': 0.09090909090909091,\n",
       " 'creates': 0.09090909090909091,\n",
       " 'trailer': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'video': 0.09090909090909091,\n",
       " 'applications': 0.09090909090909091,\n",
       " 'consumer': 0.09090909090909091,\n",
       " 'personal': 0.09090909090909091,\n",
       " 'want': 0.18181818181818182,\n",
       " 'skip': 0.09090909090909091,\n",
       " 'boring': 0.18181818181818182,\n",
       " 'repetitive': 0.09090909090909091,\n",
       " 'actions': 0.09090909090909091,\n",
       " 'Similarly': 0.09090909090909091,\n",
       " 'surveillance': 0.09090909090909091,\n",
       " 'extract': 0.09090909090909091,\n",
       " 'important': 0.09090909090909091,\n",
       " 'suspicious': 0.09090909090909091,\n",
       " 'activity': 0.09090909090909091,\n",
       " 'ignoring': 0.09090909090909091,\n",
       " 'redundant': 0.09090909090909091,\n",
       " 'frames': 0.09090909090909091,\n",
       " 'captured': 0.09090909090909091}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(word_frequencies)\n",
    "word_frequencies\n",
    "#this is the normalized frequencies of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "sentence_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to calculate the sentence score, to calculate the sentence score \n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets say our case study was 40% sentence with maximum scores\n",
    "from heapq import nlargest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.4)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to select maximum 6 sentences out of all sentences \n",
    "summary = nlargest(select_length,sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "✅ sentence_scores.get\n",
    "This is the function used to sort the dictionary items.\n",
    "sentence_scores.get(sentence) returns the score for each sentence.\n",
    "key=sentence_scores.get tells Python:\n",
    "“Sort sentences by their score values.”\n",
    "\n",
    "✅ nlargest(...)\n",
    "nlargest(N, iterable, key=...) returns the top N items from an iterable based on a sorting function.\n",
    "\n",
    "In this case:\n",
    "\n",
    "N = select_length\n",
    "iterable = sentence_scores (a dict of sentences)\n",
    "key = sentence_scores.get → so sentences are sorted by score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i need to combine these top 6 sentencs then \n",
    "\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
       " 'Image collection summarization is another application example of automatic summarization.',\n",
       " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document., The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.)., The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query., Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      ", Image collection summarization is another application example of automatic summarization., Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(summary) # we get the final summary by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client assigne this work nlp enginner -- share this text to client for evaluiton \n",
    "# reduce manual work \n",
    "# still pen adn paper "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
